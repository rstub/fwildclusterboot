boottest.lm <- function(object,
clustid,
param,
B,
debug = FALSE,
seed = NULL){
#' method for object of class "lm"
#'@export
boottest.lm <- function(object,
clustid,
param,
B,
debug = FALSE,
seed = NULL){
#' method for object of class "lm"
#'@export
boottest.lm <- function(object,
clustid,
param,
B,
debug = FALSE,
seed = NULL){
#' method for object of class "lm"
#'@export
boottest.lm <- function(object,
clustid,
param,
B,
debug = FALSE,
seed = NULL){
boottest.lm <- function(object,
clustid,
param,
B,
debug = FALSE,
seed = NULL){
if(!is.null(seed)){
set.seed(seed)
} else if(is.null(seed)){
set.seed(2)
}
# retrieve clusters / multiple clusters
if(inherits(clustid, "formula")) {
clustid_tmp <- expand.model.frame(object, clustid, na.expand = FALSE)
clustid <- model.frame(clustid, clustid_tmp, na.action = na.pass)
} else {
clustid <- as.data.frame(clustid, stringsAsFactors = FALSE)
}
if(!(param %in% c(names(object$coefficients)))){
warning("Parameter to test not in model or all. Please specify appropriate parameters to test.")
}
# how many clustids? uniway/multiway?
clustid_dims <- ncol(clustid)
# Handle omitted or excluded observations
if(!is.null(object$na.action)) {
if(class(object$na.action) == "exclude") {
clustid <- clustid[-object$na.action,]
} else if(class(object$na.action) == "omit") {
clustid <- clustid[-object$na.action,]
}
clustid <- as.data.frame(clustid)  # silly error somewhere
}
#if(debug) print(class(clustid))
# Factors in our clustiding variables can potentially cause problems
# Blunt fix is to force conversion to characters
i <- !sapply(clustid, is.numeric)
clustid[i] <- lapply(clustid[i], as.character)
# Make all combinations of clustid dimensions
# if(clustid_dims > 1) {
#   for(i in acc) {
#     clustid <- cbind(clustid, Reduce(paste0, clustid[,i]))
#   }
# }
# start estimation here:
R0 <- as.numeric(param == names(object$coefficients))
groupvars <- names(coef(object))
# if(object_type == "felm"){
#
#   depvar <- names(object$response)
#   Y <- object$response
#   X <- lfe:::model.matrix.felm(felm_fit)
# }
depvar <- all.vars(as.formula(object$call))[1]
#measurevar <- "y"
#formula <- as.formula(paste(measurevar, paste(groupvars, collapse=" + "), sep=" ~ "))
X <- model.matrix(as.formula(object$call), object$model)
Y <- as.matrix(model.frame(object)[, depvar])
N <- length(Y)
k <- ncol(X)
Xr <- X[, -which(R0 == 1)] # delete rows that will be tested
#clustid <- as.vector(clustid)
#clustid <- rep(1:20, 100)
N_G <- nrow(unique(clustid)) #number of clusters
if(N_G > 2000){
warning(paste("You are estimating a model with more than 200 clusters. Are you sure you want to proceed with bootstrap standard errors instead of asymptotic sandwich standard errors? The more clusters in the data, the longer the estimation process."))
}
# error under the null hypothesis
u_hat <- Y - Xr %*% solve(t(Xr) %*% Xr) %*% t(Xr) %*% Y # N x 1 matrix
invXX <- solve(t(X) %*% X) # k x k matrix
v <- matrix(sample(c(1, -1), N_G * (B + 1), replace = TRUE), N_G, B + 1) # rademacher weights for all replications
v[,1] <- 1
XinvXXr <- X %*% (invXX %*% R0) # N x 1
SXinvXXRu_prep <- data.table::data.table(prod = XinvXXr * matrix(rep(u_hat, 1), N, 1) , clustid = clustid)
SXinvXXRu <- as.matrix(SXinvXXRu_prep[, lapply(.SD, sum), by = "clustid.clustid"][, clustid.clustid := NULL])
if(ncol(SXinvXXRu) == 1){
SXinvXXRu <- as.vector(SXinvXXRu)
}
SXinvXXRX_prep <- data.table::data.table(prod = matrix(rep(XinvXXr, k), N, k) * X, clustid = clustid)
SXinvXXRX <- as.matrix(SXinvXXRX_prep[, lapply(.SD, sum), by = "clustid.clustid"][, clustid.clustid := NULL])
SXu_prep <- data.table::data.table(prod = X * matrix(rep(u_hat, k), N, k), clustid = clustid)
SXu <- as.matrix(SXu_prep[, lapply(.SD, sum), by = "clustid.clustid"][, clustid.clustid := NULL])
numer <- SXinvXXRu %*% v
J <- (diag(SXinvXXRu) - SXinvXXRX  %*% invXX %*% t(SXu)) %*% v
t <- abs(numer)  / sqrt(colSums(J * J))
p_val <- mean(t[1] < t[2:(B + 1)])
paste("The wild cluster bootstrap p-value for the parameter", param, "is", p_val, ",", "with B", B,  "bootstrap iterations.")
}
boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = "x")
names(coef(lm_fit))
sapply(names(coef(lm_fit)), boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = x))
lapply(i %in% names(coef(lm_fit)), function(i) boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = i))
lapply(i in names(coef(lm_fit)), function(i) boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = i))
lapply(list(names(coef(lm_fit))), function(i) boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = i))
list(names(coef(lm_fit)))
(names(coef(lm_fit)))
(names(coef(lm_fit)))[1]
(names(coef(lm_fit)))[2]
lapply(1:length(names(coef(lm_fit))), function(i) boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = names(coef(lm_fit))[i])
)
vboot <- Vectorize(boottest.lm_robust, vectorize.args = "param")
vboot(lm_robust_fit, data = data, clustid = data$cluster, B = B, seed = seed, param = c("(Intercept)", "x"))
vboot <- Vectorize(boottest.lm_robust, vectorize.args = "param")
vboot <- Vectorize(boottest.lm_robust, vectorize.args = "param")
vboot(lm_robust_fit, data = data, clustid = data$cluster, B = B, seed = seed, param = "x")
lm_robust_fit
seed <- sample(1:1000, 1)
seed
gen_cluster <- function(param = c(1, 0), n = 20000, n_cluster = 50, rho = .8) {
# source: https://yukiyanai.github.io/teaching/rm1/contents/R/clustered-data-analysis.html
# Function to generate clustered data
# Required package: mvtnorm
# individual level
Sigma_i <- matrix(c(1, 0, 0, 1 - rho), ncol = 2)
values_i <- rmvnorm(n = n, sigma = Sigma_i)
# cluster level
cluster_name <- rep(1:n_cluster, each = n / n_cluster)
Sigma_cl <- matrix(c(1, 0, 0, rho), ncol = 2)
values_cl <- rmvnorm(n = n_cluster, sigma = Sigma_cl)
# predictor var consists of individual- and cluster-level components
x <- values_i[ , 1] + rep(values_cl[ , 1], each = n / n_cluster)
# error consists of individual- and cluster-level components
error <- values_i[ , 2] + rep(values_cl[ , 2], each = n / n_cluster)
# data generating process
y <- param[1] + param[2]*x + error
df <- data.frame(x, y, cluster = cluster_name)
data.table::setDT(df)
return(df)
}
#
data <- gen_cluster()
#head(data)
#data[, mean(y)]
lm_fit <- lm(y ~ x, data = data)
# standard bootstrap
B <- 10000
lmtest::coeftest(lm_fit, boot_fit)
boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = "(Intercept)")
boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = "x")
lm_robust_fit <- lm_robust(y ~ x, data = data, clusters = cluster)
lm_robust_fit %>%
summary()
boottest.lm_robust(lm_robust_fit, data = data, clustid = data$cluster, B = B, seed = seed, param = "x")
vboot <- Vectorize(boottest.lm_robust, vectorize.args = "param")
vboot(lm_robust_fit, data = data, clustid = data$cluster, B = B, seed = seed, param = "x")
#' method for object of class "lm"
#'@export
boottest.lm <- function(object,
clustid,
param,
B,
debug = FALSE,
seed = NULL){
if(!is.null(seed)){
set.seed(seed)
} else if(is.null(seed)){
set.seed(2)
}
# retrieve clusters / multiple clusters
if(inherits(clustid, "formula")) {
clustid_tmp <- expand.model.frame(object, clustid, na.expand = FALSE)
clustid <- model.frame(clustid, clustid_tmp, na.action = na.pass)
} else {
clustid <- as.data.frame(clustid, stringsAsFactors = FALSE)
}
if(!(param %in% c(names(object$coefficients)))){
warning("Parameter to test not in model or all. Please specify appropriate parameters to test.")
}
# how many clustids? uniway/multiway?
clustid_dims <- ncol(clustid)
# Handle omitted or excluded observations
if(!is.null(object$na.action)) {
if(class(object$na.action) == "exclude") {
clustid <- clustid[-object$na.action,]
} else if(class(object$na.action) == "omit") {
clustid <- clustid[-object$na.action,]
}
clustid <- as.data.frame(clustid)  # silly error somewhere
}
#if(debug) print(class(clustid))
# Factors in our clustiding variables can potentially cause problems
# Blunt fix is to force conversion to characters
i <- !sapply(clustid, is.numeric)
clustid[i] <- lapply(clustid[i], as.character)
# Make all combinations of clustid dimensions
# if(clustid_dims > 1) {
#   for(i in acc) {
#     clustid <- cbind(clustid, Reduce(paste0, clustid[,i]))
#   }
# }
# start estimation here:
R0 <- as.numeric(param == names(object$coefficients))
groupvars <- names(coef(object))
# if(object_type == "felm"){
#
#   depvar <- names(object$response)
#   Y <- object$response
#   X <- lfe:::model.matrix.felm(felm_fit)
# }
depvar <- all.vars(as.formula(object$call))[1]
#measurevar <- "y"
#formula <- as.formula(paste(measurevar, paste(groupvars, collapse=" + "), sep=" ~ "))
X <- model.matrix(as.formula(object$call), object$model)
Y <- as.matrix(model.frame(object)[, depvar])
N <- length(Y)
k <- ncol(X)
Xr <- X[, -which(R0 == 1)] # delete rows that will be tested
#clustid <- as.vector(clustid)
#clustid <- rep(1:20, 100)
N_G <- nrow(unique(clustid)) #number of clusters
if(N_G > 2000){
warning(paste("You are estimating a model with more than 200 clusters. Are you sure you want to proceed with bootstrap standard errors instead of asymptotic sandwich standard errors? The more clusters in the data, the longer the estimation process."))
}
# error under the null hypothesis
u_hat <- Y - Xr %*% solve(t(Xr) %*% Xr) %*% t(Xr) %*% Y # N x 1 matrix
invXX <- solve(t(X) %*% X) # k x k matrix
v <- matrix(sample(c(1, -1), N_G * (B + 1), replace = TRUE), N_G, B + 1) # rademacher weights for all replications
v[,1] <- 1
XinvXXr <- X %*% (invXX %*% R0) # N x 1
SXinvXXRu_prep <- data.table::data.table(prod = XinvXXr * matrix(rep(u_hat, 1), N, 1) , clustid = clustid)
SXinvXXRu <- as.matrix(SXinvXXRu_prep[, lapply(.SD, sum), by = "clustid.clustid"][, clustid.clustid := NULL])
if(ncol(SXinvXXRu) == 1){
SXinvXXRu <- as.vector(SXinvXXRu)
}
SXinvXXRX_prep <- data.table::data.table(prod = matrix(rep(XinvXXr, k), N, k) * X, clustid = clustid)
SXinvXXRX <- as.matrix(SXinvXXRX_prep[, lapply(.SD, sum), by = "clustid.clustid"][, clustid.clustid := NULL])
SXu_prep <- data.table::data.table(prod = X * matrix(rep(u_hat, k), N, k), clustid = clustid)
SXu <- as.matrix(SXu_prep[, lapply(.SD, sum), by = "clustid.clustid"][, clustid.clustid := NULL])
numer <- SXinvXXRu %*% v
J <- (diag(SXinvXXRu) - SXinvXXRX  %*% invXX %*% t(SXu)) %*% v
t <- abs(numer)  / sqrt(colSums(J * J))
p_val <- mean(t[1] < t[2:(B + 1)])
paste("The wild cluster bootstrap p-value for the parameter", param, "is", p_val, ",", "with B", B,  "bootstrap iterations.")
}
vboot(lm_robust_fit, data = data, clustid = data$cluster, B = B, seed = seed, param = "x")
vboot <- Vectorize(boottest.lm_robust, vectorize.args = "param")
vboot(lm_robust_fit, data = data, clustid = data$cluster, B = B, seed = seed, param = "x")
lm_fit
object <- lm_fit
clustid = data$cluster
param <- names(coef(object))
param
length(param)
B <- 200
debug = FALSE
seed
R0 <- as.numeric(param == names(object$coefficients))
R0
groupvars <- names(coef(object))
depvar <- all.vars(as.formula(object$call))[1]
X <- model.matrix(as.formula(object$call), object$model)
Y <- as.matrix(model.frame(object)[, depvar])
N <- length(Y)
k <- ncol(X)
Xr <- X[, -which(R0 == 1)] # delete rows that will be tested
Xr
dim(Xr)
#clustid <- as.vector(clustid)
#clustid <- rep(1:20, 100)
N_G <- nrow(unique(clustid)) #number of clusters
if(N_G > 2000){
warning(paste("You are estimating a model with more than 200 clusters. Are you sure you want to proceed with bootstrap standard errors instead of asymptotic sandwich standard errors? The more clusters in the data, the longer the estimation process."))
}
# error under the null hypothesis
u_hat <- Y - Xr %*% solve(t(Xr) %*% Xr) %*% t(Xr) %*% Y # N x 1 matrix
library(fwildclusterboot)
seed <- sample(1:1000, 1)
seed
gen_cluster <- function(param = c(1, 0), n = 20000, n_cluster = 50, rho = .8) {
# source: https://yukiyanai.github.io/teaching/rm1/contents/R/clustered-data-analysis.html
# Function to generate clustered data
# Required package: mvtnorm
# individual level
Sigma_i <- matrix(c(1, 0, 0, 1 - rho), ncol = 2)
values_i <- rmvnorm(n = n, sigma = Sigma_i)
# cluster level
cluster_name <- rep(1:n_cluster, each = n / n_cluster)
Sigma_cl <- matrix(c(1, 0, 0, rho), ncol = 2)
values_cl <- rmvnorm(n = n_cluster, sigma = Sigma_cl)
# predictor var consists of individual- and cluster-level components
x <- values_i[ , 1] + rep(values_cl[ , 1], each = n / n_cluster)
# error consists of individual- and cluster-level components
error <- values_i[ , 2] + rep(values_cl[ , 2], each = n / n_cluster)
# data generating process
y <- param[1] + param[2]*x + error
df <- data.frame(x, y, cluster = cluster_name)
data.table::setDT(df)
return(df)
}
#
data <- gen_cluster()
library(mvtnorm)
library(magrittr)
gen_cluster <- function(param = c(1, 0), n = 20000, n_cluster = 50, rho = .8) {
# source: https://yukiyanai.github.io/teaching/rm1/contents/R/clustered-data-analysis.html
# Function to generate clustered data
# Required package: mvtnorm
# individual level
Sigma_i <- matrix(c(1, 0, 0, 1 - rho), ncol = 2)
values_i <- rmvnorm(n = n, sigma = Sigma_i)
# cluster level
cluster_name <- rep(1:n_cluster, each = n / n_cluster)
Sigma_cl <- matrix(c(1, 0, 0, rho), ncol = 2)
values_cl <- rmvnorm(n = n_cluster, sigma = Sigma_cl)
# predictor var consists of individual- and cluster-level components
x <- values_i[ , 1] + rep(values_cl[ , 1], each = n / n_cluster)
# error consists of individual- and cluster-level components
error <- values_i[ , 2] + rep(values_cl[ , 2], each = n / n_cluster)
# data generating process
y <- param[1] + param[2]*x + error
df <- data.frame(x, y, cluster = cluster_name)
data.table::setDT(df)
return(df)
}
#
data <- gen_cluster()
lm_fit <- lm(y ~ x, data = data)
# standard bootstrap
B <- 1000
B <- 1000
boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = "x")
library(data.table)
boottest.lm(lm_fit, clustid = data$cluster, B = B, seed = seed, param = "x")
install.packages("data.table")
.libPaths()
bothPaths <- .libPaths()   # extract both paths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
bothPaths <- .libPaths()   # extract both paths
bothPaths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
# create a list of all installed packages
ip <- as.data.frame(installed.packages())
head(ip)
# if you use MRO, make sure that no packages in this library will be removed
ip <- subset(ip, !grepl("MRO", ip$LibPath))
# we don't want to remove base or recommended packages either\
ip <- ip[!(ip[,"Priority"] %in% c("base", "recommended")),]
# determine the library where the packages are installed
path.lib <- unique(ip$LibPath)
# create a vector with all the names of the packages you want to remove
pkgs.to.remove <- ip[,1]
head(pkgs.to.remove)
# remove the packages
sapply(pkgs.to.remove, remove.packages, lib = path.lib)
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
bothPaths <- .libPaths()   # extract both paths
bothPaths
bothPaths <- .libPaths()   # extract both paths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
bothPaths
bothPaths <- .libPaths()   # extract both paths
bothPaths
bothPaths <- .libPaths()   # extract both paths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
bothPaths
bothPaths <- .libPaths()   # extract both paths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
bothPaths
bothPaths <- .libPaths()   # extract both paths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
bothPaths
bothPaths <- .libPaths()   # extract both paths
bothPaths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
.libPaths()
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("data.table")
bothPaths <- .libPaths()   # extract both paths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
bothPaths
bothPaths <- .libPaths()
bothPaths
bothPaths <- c(bothPaths [2], bothPaths [1])
.libPaths(bothPaths )
library(data.table)
library(estimatr)
library(magrittr)
library(mvtnorm)
library(multiwayvcov)
library(lmtest)
library(lfe)
install.packages(c("daa.table", "estimatr", "magrittr", "mvtnorm", "multiwayvcov", "lmtest", "lfe"))
install.packages("estimatr")
install.packages("estimatr")
install.packages("magrittr")
install.packages("mvtnorm")
install.packages(c("multiwayvcov", "lmtest", "lfe"))
setwd("C:/Users/au563468/Dropbox")
devtools::install("fwildclusterboot")
install.packages("devtools")
bothPaths <- .libPaths()   # extract both paths
bothPaths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
.libPaths()
install.packages("devtools")
install.packages("data.table", "magrittr", "mvtnorm", "lfe", "estimatr", "multiwayvcoc", "rmarkdown")
install.packages(c("data.table", "magrittr", "mvtnorm", "lfe", "estimatr", "multiwayvcoc", "rmarkdown"))
2 + 2
2 + 5
2 + 2
install.packages("data.table")
.libPaths( c( "C:/Program Files/R/custom_library" , .libPaths() ) )
.libPaths()
install.packages("data.table")
.libPaths( c( "C:/Program Files/R/r_library" , .libPaths() ) )
.libPaths()
.libPaths( c( "C:/Program Files/R/r_library" , .libPaths() ) )
.libPaths()
.libPaths( c( "C:/Program Files/r_library" , .libPaths() ) )
.libPaths()
install.packages("data.table")
install.packages("rstan")
find_rtools()
install.packages("devtools")
install.packages("devtools")
bothPaths <- .libPaths()   # extract both paths
bothPaths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
bothPaths
bothPaths <- .libPaths()   # extract both paths
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
.libPaths(bothPaths )  # modify the order
.libPaths()
install.packages("data.table")
bothPaths <- c(bothPaths [2], bothPaths [1])  # change order
bothPaths
.libPaths(bothPaths )  # modify the order
.libPaths()
library(devtools)
install.packages("devtools")
install.packages("devtools")
install.packages("data.table")
install.packages("rmarkdown")
Rcpp::evalCpp("2 + 2")
install.packages("data.table")
install.packages("rmarkdown")
install.packages("xfun")
install.packages("xfun")
library(xfun)
install.packages("xfun")
install.packages("Rcpp")
library(Rcpp)
install.packages("devtools")
library(devtools)
# create a list of all installed packages
ip <- as.data.frame(installed.packages())
head(ip)
# if you use MRO, make sure that no packages in this library will be removed
ip <- subset(ip, !grepl("MRO", ip$LibPath))
# we don't want to remove base or recommended packages either\
ip <- ip[!(ip[,"Priority"] %in% c("base", "recommended")),]
# determine the library where the packages are installed
path.lib <- unique(ip$LibPath)
# create a vector with all the names of the packages you want to remove
pkgs.to.remove <- ip[,1]
head(pkgs.to.remove)
# remove the packages
sapply(pkgs.to.remove, remove.packages, lib = path.lib)
# create a list of all installed packages
ip <- as.data.frame(installed.packages())
head(ip)
# if you use MRO, make sure that no packages in this library will be removed
ip <- subset(ip, !grepl("MRO", ip$LibPath))
# we don't want to remove base or recommended packages either\
ip <- ip[!(ip[,"Priority"] %in% c("base", "recommended")),]
# determine the library where the packages are installed
path.lib <- unique(ip$LibPath)
# create a vector with all the names of the packages you want to remove
pkgs.to.remove <- ip[,1]
head(pkgs.to.remove)
# remove the packages
sapply(pkgs.to.remove, remove.packages, lib = path.lib)
