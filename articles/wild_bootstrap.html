<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="fwildclusterboot">
<title>Wild (Cluster) Bootstrap 101 • fwildclusterboot</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Wild (Cluster) Bootstrap 101">
<meta property="og:description" content="fwildclusterboot">
<meta property="og:image" content="https://s3alfisc.github.io/fwildclusterboot/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">fwildclusterboot</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.14.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/fwildclusterboot.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/Different-Variants-of-the-Wild-Cluster-Bootstrap.html">Different Variants of the Wild Cluster Bootstrap</a>
    <a class="dropdown-item" href="../articles/Multiple-Estimations-with-fixest.html">fwildclusterboot and fixest</a>
    <a class="dropdown-item" href="../articles/Wild-Cluster-Bootstrap-Inference-in-Stata-Julia-and-Python.html">Wild Cluster Bootstrap Inference in Stata, Julia and Python</a>
    <a class="dropdown-item" href="../articles/WildBootTests.html">WildBootTests.jl</a>
    <a class="dropdown-item" href="../articles/wild_bootstrap.html">Wild (Cluster) Bootstrap 101</a>
    <a class="dropdown-item" href="../articles/Literature.html">Literature on the Wild Bootstrap and Clustered Inference in Regression Models</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/s3alfisc/fwildclusterboot/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="wild_bootstrap_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Wild (Cluster) Bootstrap 101</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/s3alfisc/fwildclusterboot/blob/HEAD/vignettes/articles/wild_bootstrap.Rmd" class="external-link"><code>vignettes/articles/wild_bootstrap.Rmd</code></a></small>
      <div class="d-none name"><code>wild_bootstrap.Rmd</code></div>
    </div>

    
    
<div class="section level3">
<h3 id="wild-cluster-bootstrap-101">Wild Cluster Bootstrap 101<a class="anchor" aria-label="anchor" href="#wild-cluster-bootstrap-101"></a>
</h3>
<p>We are interested in testing a linear hypothesis <span class="math inline">\(H_0: \beta_{j} = 0\)</span> against <span class="math inline">\(H_1: \beta_{j} \neq 0\)</span></p>
<p>for a linear model of interest</p>
<p><span class="math display">\[\begin{align}
y &amp;= X \beta + u \\
  &amp;=
\begin{bmatrix}
y_{1} \\
y_{2} \\
...\\
y_{G}
\end{bmatrix}
=
\begin{bmatrix}
X_{1} \\
X_{2} \\
...\\
X_{G}
\end{bmatrix} \beta +
\begin{bmatrix}
u_{1} \\
u_{2} \\
...\\
u_{G}
\end{bmatrix},
\end{align}\]</span></p>
<p>with <span class="math inline">\(E(u|X) = 0\)</span>, where group <span class="math inline">\(g\)</span> contains <span class="math inline">\(N_{g}\)</span> observations so that <span class="math inline">\(N = \sum_{g = 1}^{G} N_{g}\)</span>. The regression residuals <span class="math inline">\(u\)</span> are allowed to be correlated within clusters, but are assumed to be uncorrelated across clusters. In consequence, the models’ covariance matrix is block diagonal. For each cluster, we denote <span class="math inline">\(E(u_{g} u_{g}') =\Sigma_{g}\)</span> and <span class="math inline">\(E(u u') =\Sigma\)</span>.</p>
<p>A generic wild bootstrap test then proceeds in the following steps:</p>
<div class="callout">
<ul>
<li>Step 1: Either
<ul>
<li>… regress <span class="math inline">\(y\)</span> on <span class="math inline">\(X\)</span>; obtain point estimates <span class="math inline">\(\hat{\beta}\)</span> and estimated residuals <span class="math inline">\(\hat{u}\)</span>; This type of bootstrap is known as the “WCU” (wild cluster unrestricted)</li>
<li>… or regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> imposing the null (via restricted least squares); obtain point estimates <span class="math inline">\(\tilde{\beta}\)</span> and estimated residuals <span class="math inline">\(\tilde{u}\)</span>. This type of bootstrap is known as the “WCR” (wild cluster restricted)</li>
<li>to unify notation, we will denote <span class="math inline">\(\ddot{\beta}\)</span>, with <span class="math inline">\(\ddot{\beta} = \hat{\beta}\)</span> for the WCU and <span class="math inline">\(\ddot{\beta} = \tilde{\beta}\)</span> for the WCR</li>
</ul>
</li>
<li>Step 2:
<ul>
<li>calculate the (cluster) robust t-statistic for the null hypothesis of interest, i.e. <span class="math display">\[
t_{j} = \frac{\hat{\beta_{j}}}{\sqrt{\hat{\Sigma}_{jj,x}}}
\]</span> The subscript <span class="math inline">\(x\)</span> for the variance-covariance estimate <span class="math inline">\(\hat{\Sigma}_{jj,x}\)</span> denotes the type <span class="math inline">\(x\)</span> of the employed cluster robust variance estimator, and the <span class="math inline">\(jj\)</span> subscribt selects the jth column and row of the variance covariance matrix.</li>
</ul>
</li>
<li>Step 3:
<ul>
<li>For <span class="math inline">\(b = 1, ..., B\)</span> bootstrap iterations, create
<ul>
<li>a set of bootstrap error terms <span class="math inline">\(v_{b}^{*} \in \mathbb{R}^{G}\)</span>
</li>
<li>a new bootstrap sample <span class="math inline">\(y_{b}^{*} = X \ddot{\beta} + f_{y}(\hat{u}) \times v_{b}^{*}\)</span>, where for each observation from the same cluster g, the transformed predicted error <span class="math inline">\(f_{y}(\hat{u})\)</span> is multiplied with the same weight <span class="math inline">\(v_{b,g}^{*}\)</span>
</li>
<li>a bootstrapped t-statistic <span class="math display">\[
 t_{j,b}^{*} = \frac{\hat{\beta_{j,b}^{*}} - \ddot{\beta_{j}}}{\sqrt{\hat{\Sigma}_{jj,x,b}^{*}}}
  \]</span> where <span class="math inline">\(\hat{\beta}_{j,b}^{*}\)</span> is the jth element of the OLS estimate of <span class="math inline">\(y_{b}^{*}\)</span> on <span class="math inline">\(X\)</span> and <span class="math inline">\(\hat{\Sigma}_{jj, x, b}^{*}\)</span> the associated (cluster) robust variance-covariance estimate of type <span class="math inline">\(x\)</span>
</li>
</ul>
</li>
</ul>
</li>
<li>Step 4:
<ul>
<li>based on all <span class="math inline">\(B\)</span> bootstrapped t-statistics, calculate a bootstrap p-value as</li>
</ul>
<span class="math display">\[\begin{equation}
  \text{left-tailed: } \hat{P}_{L}^{*} = \frac{1}{B} \sum_{b = 1}^{B} 1(t^{*}_{j,b} &lt; t_{j})
\end{equation}\]</span>
</li>
</ul>
<p><span class="math display">\[\begin{equation}
\text{right tailed: } \hat{P}_{R}^{*} = \frac{1}{B} \sum_{b = 1}^{B} 1(t^{*}_{j,b} &gt; t_j)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
   \text{two-tailed: }   \hat{P}_{S}^{*} = \frac{1}{B} \sum_{b = 1}^{B} 1(|t^{*}_{j,b}| &gt; |t_j|)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\text{equal-tailed: } \hat{P}_{ET}^{*} = 2 min(\hat{P}_{L}^{*}, \hat{P}_{R}^{*}).
\end{equation}\]</span></p>
</div>
</div>
<div class="section level3">
<h3 id="multiple-variants-of-the-wild-cluster-bootstrap">Multiple Variants of the Wild Cluster Bootstrap<a class="anchor" aria-label="anchor" href="#multiple-variants-of-the-wild-cluster-bootstrap"></a>
</h3>
<p>The above algorithm leads to several variants of the wild cluster bootstrap: first, the bootstrap variants may differ in the choice of the variance-covariance estimator <span class="math inline">\(\Sigma_{x}\)</span>. Second, they may differ in the functional transformation of the estimated residuals <span class="math inline">\(f(\hat{u})\)</span>. Finally, the choice of imposing or not imposing the null on the bootstrap data generating process, as well as the choice of bootstrap weights lead to different bootstrap variants.</p>
<p>Based on recent work by <span class="citation">J. G. MacKinnon et al. (2022)</span>, we will put emphasis on the choice of the variance-covariance estimator <span class="math inline">\(\Sigma_{x}\)</span> and how the residuals <span class="math inline">\(f(\hat{u})\)</span> are transformed.</p>
<p>For reasons of computational feasibility, <span class="citation">J. G. MacKinnon et al. (2022)</span> focus on CRV1 and CRV3 covariance matrix estimators.</p>
<p>Both the CRV1 and CRV3 variance covariance estimators can be written as</p>
<p><span class="math display">\[\begin{equation}
  CRV: \hat{\Sigma}_{x} = (X'X)^{-1} (\sum_{g=1}^{G} X_{g}' f_{x}(\hat{u}_{g}) f_{x}(\hat{u}_{g})' X_{g} ) (X'X)^{-1}.
\end{equation}\]</span></p>
<p>For the CRV1 estimator, the function <span class="math inline">\(f_{1}(\hat{u}_{g})'\)</span> is defined as</p>
<p><span class="math display">\[
  f_{1}(\hat{u}_{g})' = \sqrt{\frac{G}{G-1} \frac{N-1}{N-k}} \times \hat{u}.
\]</span></p>
<p>For the CRV3 estimator, the equivalent function is defined as</p>
<p><span class="math display">\[
  f_{3}(\hat{u}_{g})' = \sqrt{\frac{G}{G-1}} \times M_{gg}^{-1} \hat{u}_{g}
\]</span></p>
<p>where <span class="math inline">\(M_{gg} = I_{N_g} - H_g\)</span>, <span class="math inline">\(H_g = X_g (X'X)^{-1} X_g'\)</span>, and <span class="math inline">\(I_{N_g}\)</span> is the diagonal matrix for all observations in cluster <span class="math inline">\(g\)</span>.</p>
<p>In consequence, <span class="citation">J. G. MacKinnon et al. (2022)</span> define four distinct bootstrap variants that differ in a) the function <span class="math inline">\(f_{y}\)</span> used when creating the bootstrap samples - i.e. whether the “score” is imposed on the bootstrap data generating process or not - and b) the the type of variance-covariance matrix estimator, which can either be the classical CRV1 or the CRV3 estimator.</p>
<table class="table">
<caption>Overview of different bootstrap variants {#tbl-bootstrap-variants}</caption>
<thead><tr class="header">
<th align="center">Bootstrap Type</th>
<th align="center">VCOV</th>
<th align="center">Score-on-dgp</th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">‘Classic’: ‘C’(‘11’)</td>
<td align="center">CRV1</td>
<td align="center"><span class="math inline">\(f_{1}\)</span></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">‘Variance’: ‘V’(‘13’)</td>
<td align="center">CRV3</td>
<td align="center"><span class="math inline">\(f_{1}\)</span></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">‘Score’: ‘S’(‘31’)</td>
<td align="center">CRV1</td>
<td align="center"><span class="math inline">\(f_{3}\)</span></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">‘Both’: ‘B’(‘33’)</td>
<td align="center">CRV3</td>
<td align="center"><span class="math inline">\(f_{3}\)</span></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>All four variants of the wild cluster bootstrap are supported via <span class="pkg">fwildclusterboot</span>, either imposing the null hypothesis on the bootstrap data generating process (WCR) or not (WCU).</p>
</div>
<div class="section level3">
<h3 id="multi-way-clustering">Multi-Way Clustering<a class="anchor" aria-label="anchor" href="#multi-way-clustering"></a>
</h3>
<p>A further generalisation of the algorithm described above is the case of multi-way clustering. For multi-way clustering over two sets of clusters <span class="math inline">\(G\)</span> and <span class="math inline">\(H\)</span>, the variance-covariance matrix is computed as</p>
<p><span class="math display">\[\begin{equation}
  \hat{\Sigma} = m_{G} \hat{\Sigma}_{G} +  m_{H} \hat{\Sigma}_{H} - m_{GH} \hat{\Sigma}_{GH}
\end{equation}\]</span></p>
<p>where the number of clusters in <span class="math inline">\(m_{GH}\)</span> is the number of non-empty intersections in clusters <span class="math inline">\(G\)</span> and <span class="math inline">\(H\)</span> (and the variance covariance matrix estimator <span class="math inline">\(\hat{\Sigma}_{i}\)</span> can be either CRV1 or CRV3 for all <span class="math inline">\(i \in \{G, H, GH \}\)</span>). Note that it may occur that the resulting variance-covariance matrix is not positive definite - in this case, bootstrap estimates are discarded.</p>
<p>An important choice for multi-way clustering is the level from which the bootstrap weights are drawn: Should the bootstrap weights be drawn from cluster <span class="math inline">\(G\)</span>, cluster <span class="math inline">\(H\)</span>, or even the intersection of the two? The level of clustering from which the bootstrap weights are drawn is usually referred to as the “bootcluster”. By default, <span class="pkg">boottest</span> and <span class="pkg">fwildclusterboot</span> select the <em>largest</em> of the three clustering levels as the bootcluster, although this is not necessarily recommended (see <span class="citation">Roodman et al. (2019)</span>).</p>
<p>For applications with few treated clusters - for example, difference-in-differences models with few treated states - <span class="citation">MacKinnon and Webb (2018)</span> suggest using a ‘subcluster’ as the level of sampling for the bootstrap weights. A subcluster is a partition of a cluster, i.e. cities in a given state.</p>
</div>
<div class="section level3">
<h3 id="the-non-clustered-wild-bootstrap">The Non-Clustered Wild Bootstrap<a class="anchor" aria-label="anchor" href="#the-non-clustered-wild-bootstrap"></a>
</h3>
<p>For the non-clustered (“heteroskedastic”) wild bootstrap, each observation is multiplied by its own ‘custom’ weight, and the cluster-robust variance-covariance matrices are replaced by <em>heteroskedastic</em> variance-covariance matrices. This results in the following functional specifications:</p>
<p><span class="math display">\[\begin{equation}
  HC1: f(\hat{u}) = \sqrt{\frac{n}{n-k}} \hat{u}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
HC2: f(\hat{u}) = \frac{\hat{u}}{(1-h_i)^{1/2}};
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
HC3:  f(\hat{u}) = \frac{\hat{u}}{(1-h_i)}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(h_i\)</span> is the i-th diagonal element of the “hat-matrix” <span class="math inline">\(P_x = X(X'X)^{-1}X'\)</span>.</p>
<p>At the moment, <span class="pkg">fwildclusterboot</span> only supports the ‘11’, ‘21’ and ‘31’ combinations of the wild robust bootstrap, i.e. one can choose to apply the ‘HC1’, ‘HC2’ or ‘HC3’ correction on the bootstrap data generating process, but the bootstrap variance-covariance matrices are always calculated via ‘HC1’.</p>
</div>
<div class="section level3">
<h3 id="different-bootstrap-weights">Different bootstrap weights<a class="anchor" aria-label="anchor" href="#different-bootstrap-weights"></a>
</h3>
<p>One last degree of freedom when conducting inference via a wild bootstrap is the type of bootstrap weights, i.e. the choice of probability distribution from which the weights are drawn. <span class="pkg">fwildclusterboot</span> offers support for four distinct weights <span class="math inline">\(v_{b}^{*}\)</span>:</p>
<ul>
<li>
<em>Rademacher weights</em> take values <span class="math inline">\(1\)</span> and <span class="math inline">\(-1\)</span> with equal probability</li>
<li>
<em>Mammen weights</em> take values values <span class="math inline">\(1-\psi\)</span> with probability <span class="math inline">\(\psi / \sqrt(5)\)</span> and <span class="math inline">\(\psi\)</span> otherwise, with <span class="math inline">\(\psi = (1+\sqrt(5))/2\)</span>
</li>
<li>
<em>Normal weights</em> draw from the standard normal distribution</li>
<li>
<em>Webb weights</em> draw from a six-point distribution, each with probability <span class="math inline">\(1/6\)</span>. Possible values are <span class="math inline">\(+/-1.5, +/-1, +/-0.5\)</span>.</li>
</ul>
<p>For Rademacher and Mammen weights, only <span class="math inline">\(2^G\)</span> unique combinations of draws exist. If G is small - i.e. smaller than 12 - it is therefore often recommended to use Webb weights with <span class="math inline">\(6^G\)</span> unique possible draws (see <span class="citation">Webb (2013)</span>).</p>
</div>
<div class="section level3">
<h3 id="wild-bootstrap-confidence-intervals">Wild Bootstrap Confidence Intervals<a class="anchor" aria-label="anchor" href="#wild-bootstrap-confidence-intervals"></a>
</h3>
<p>In theory, multiple ways to calculate wild (cluster) bootstrapped confidence intervals exists <span class="citation">(J. G. MacKinnon, Nielsen, and Webb 2022)</span>. <!-- If the null hypothesis is not imposed on the bootstrap dgp, --> <!-- The most straightforward approach is to calculate a standard error $\hat{s}^{*}(\hat{\beta})$ based on the bootstrapped regression coefficients $\hat{\beta}_{b}^{*}$ and a plug-in estimator: --></p>
<!-- \begin{equation} -->
<!--  [\hat{\beta} - c_{1-\alpha / 2}, \hat{s}^{*}(\hat{\beta}), \hat{\beta} + c_{1-\alpha / 2}, \hat{s}^{*}(\hat{\beta})]. -->
<!-- \end{equation} -->
<!-- Here, $c_{1-\alpha / 2}$ is the $1-\alpha$ quantile of the $t(G-1)$ distribution. -->
<!-- Asymptotic refinement of the plug-in estimator can be achieved by using as studentized version of the confidence interval above, which is often denoted as a "t-percentile bootstrap" -->
<!-- \begin{equation} -->
<!-- [\hat{\beta} - c^{*}_{1-\alpha / 2}, \hat{s}^{*}(\hat{\beta}), \hat{\beta} + c^{*}_{1-\alpha / 2}, \hat{s}^{*}(\hat{\beta})], -->
<!-- \end{equation} -->
<!-- where $c^{*}_{1-\alpha / 2}$ is the empirical $1-\alpha / 2$ quantile of the distribution of bootstrapped t-statistics. -->
<!-- If the null hypothesis is imposed on the data generating process, the strategy above is now longer feasible.  -->
<p>Based on simulation results in <span class="citation">MacKinnon (2015)</span> and higher order asymptotic theory in <span class="citation">Djogbenou, MacKinnon, and Nielsen (2019)</span>, <span class="pkg">fwildclusterboot</span> computes confidence intervals by test inversion. While inverting bootstrap tests is computationally more demanding, in the case of the wild cluster bootstrap, the procedure can be massively accelerated by pre-computing multiple objects that are constant across all iterations of the inversion algorithm. Details on how this acceleration is achieved in <span class="pkg">fwildclusterboot</span> are presented in the appendix (which is to be added. If you are curious, you can email Alex, and he’ll share his notes). In the following section, for illustrative purposes, we will demonstrate how to invert a simple t-test for a regression model (vs a bootstrap test inversion).</p>
<!-- While inverting bootstrap tests is computationally more demanding, it allows to compute confidence intervals for the WCR bootstrap, which is generally be considered to perform better (based on both theoretical and empirical simulation evidence, see e.g. [@mackinnon2022cluster] for a discussion). In addition, the inversion of wild cluster bootstrap tests can be massively accelerated by pre-computing multiple objects that are constant across all iterations of the inversion algorithm. Details on how this acceleration is achieved in [fwildclusterboot]{.pkg} are presented in the appendix (which is to be added. If you are curious, you can email Alex, and he'll share his notes). In the following section, for illustrative purposes, we will demonstrate how to invert a simple t-test for a regression model (vs a bootstrap test inversion). -->
<div class="section level4">
<h4 id="example-how-to-compute-a-ci-by-test-inversion">Example: How to compute a CI by test inversion<a class="anchor" aria-label="anchor" href="#example-how-to-compute-a-ci-by-test-inversion"></a>
</h4>
<!-- Suppose we have a parameter $\theta \in \Theta$ and a test statistic $T(\theta)$. We also have a critical value $c$ so that to test the null hypothesis $H_0: \theta = \theta_0$ against $H_1: \theta \neq \theta_0$ at a level $\alpha$, we reject the null hypothesis if $T(\theta_0) > c$. -->
<!-- Let's define a set that includes all values of $\theta$ for which the decision rule "reject the null hypothesis if $T(\theta)\geq c$" leads to an acceptance of the null hypothesis: -->
<!-- $$ -->
<!--   C = \{\theta \in \Theta: T(\theta)\leq c \}. -->
<!-- $$ -->
<p>Based on the definition of the p-value, we can define a confidence interval at significance level <span class="math inline">\(\alpha\)</span> as</p>
<p><span class="math display">\[
  C = \{\theta \in \Theta: p(\theta) \geq \alpha \}.
\]</span> In other words: the confidence interval is the set of all values <span class="math inline">\(\theta \in \Theta\)</span> with p-value larger than the chosen significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>All of this implies that if we have a function that calculates p-values for different values of <span class="math inline">\(\theta\)</span>, <span class="math inline">\(p(\theta)\)</span>, to obtain a confidence interval, we simply have to collect all values <span class="math inline">\(\theta\)</span> for which <span class="math inline">\(p(\theta) &gt; \alpha\)</span>. Or, in other words, we need to <em>invert</em> <span class="math inline">\(p(\theta)\)</span>.</p>
<p>We will illustrate all of this based on a simple linear regression model.</p>
<p>The data generating process is</p>
<p><span class="math display">\[ 
  Y = \beta_0 + \beta_1 X + u
\]</span></p>
<p>with <span class="math inline">\(E[u|X] = 0\)</span>, and we are interested in testing the null hypothesis</p>
<p><span class="math display">\[
  H_0: \beta_1 = 0    \textit{ vs } H_1: \beta_1 \neq 0.
\]</span></p>
<p>We start with simulating the data:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">21348534</span><span class="op">)</span></span>
<span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">+</span> <span class="fl">0.01</span> <span class="op">*</span> <span class="va">X</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">X</span>, data <span class="op">=</span> <span class="va">df</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The estimated confidence interval of the regression model is</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt;                    2.5 %     97.5 %</span></span>
<span><span class="co">#&gt; (Intercept)  0.964052355 1.00325628</span></span>
<span><span class="co">#&gt; X           -0.007654199 0.03204427</span></span></code></pre></div>
<p>Note that this confidence interval is build on <em>estimated standard errors</em>.</p>
<p>This means that in order to calculate standard errors, <code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code> computes a standard error and multiplies it with a critical value.</p>
<p>To compute a confidence without estimating standard errors, we first need to define a function that calculates p-values for different values of <span class="math inline">\(\beta\)</span> given the model and data. To do so, we will simply create a function that will allow us to test hypotheses of the form</p>
<p><span class="math display">\[
  H_0: \beta_1 - r = 0    \textit{ vs } H_1: \beta_1 -r \neq 0.
\]</span></p>
<p>for different values of <span class="math inline">\(r\)</span>, which is of course equivalent to testing</p>
<p><span class="math display">\[
    H_0: \beta_1 = r     \textit{ vs } H_1: \beta_1  \neq r.
\]</span></p>
<p>Tests of such a form are implemented in the <code>car</code> package, via the <code>linearHypothesis</code> function, and we create a small wrapper function, <code>p_val(y, X, r)</code> around <code><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html" class="external-link">car::linearHypothesis</a></code>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p_val</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">X</span>, <span class="va">r</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">X</span><span class="op">)</span></span>
<span>  <span class="va">p_val</span> <span class="op">&lt;-</span> <span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html" class="external-link">linearHypothesis</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">res</span>, hypothesis.matrix <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>, rhs <span class="op">=</span> <span class="va">r</span><span class="op">)</span><span class="op">$</span><span class="va">`Pr(&gt;F)`</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span>  <span class="va">p_val</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>As can be seen in the plot below, for different values of <span class="math inline">\(r\)</span>, <code>p_val()</code> returns a range of p-values:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p_val_r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/unlist.html" class="external-link">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.005</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu">p_val</span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, X <span class="op">=</span> <span class="va">X</span>, r <span class="op">=</span> <span class="va">i</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">p_val_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>r <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.005</span><span class="op">)</span>, p_val_r <span class="op">=</span> <span class="va">p_val_r</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_val_df</span><span class="op">$</span><span class="va">r</span>, y <span class="op">=</span> <span class="va">p_val_df</span><span class="op">$</span><span class="va">p_val_r</span>,type <span class="op">=</span> <span class="st">"b"</span>, pch <span class="op">=</span> <span class="fl">20</span>, lty <span class="op">=</span> <span class="fl">2</span>, xlab <span class="op">=</span> <span class="st">"r"</span>, ylab <span class="op">=</span> <span class="st">"p-value"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">p_val_df</span><span class="op">$</span><span class="va">r</span>, <span class="va">p_val_df</span><span class="op">$</span><span class="va">p_val_r</span>, type <span class="op">=</span> <span class="st">"l"</span>, lty <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="fl">0.05</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">-</span> <span class="fl">0.01</span>, y <span class="op">=</span> <span class="fl">0.8</span>, <span class="st">"lower"</span>, srt<span class="op">=</span><span class="fl">0.2</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="fl">0.01</span>, y <span class="op">=</span> <span class="fl">0.8</span>, <span class="st">"upper"</span>, srt<span class="op">=</span><span class="fl">0.2</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">-</span> <span class="fl">0.01</span>, col <span class="op">=</span> <span class="st">"green"</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fl">0.01</span>, col <span class="op">=</span> <span class="st">"green"</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">-</span> <span class="fl">0.01</span>, col <span class="op">=</span> <span class="st">"green"</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="fl">0.01</span>, col <span class="op">=</span> <span class="st">"green"</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p><img src="wild_bootstrap_files/figure-html/unnamed-chunk-5-1.png" width="700"></p>
<p>The p-value peaks for the “true” null hypothesis <span class="math inline">\(\beta_1 = r = 0.01\)</span> and decreases when moving further away from the true value.</p>
<p>The two points where the red line crosses with the black line - marked by a blue line - are the confidence interval for our hypothesis test of interest! (Note that this plot is very similar to the output of <code><a href="../reference/plot.boottest.html">plot.boottest()</a></code>).</p>
<p>In consequence, our goal is to find the intersection of the blue, red, and black lines.</p>
<p>To do so, we need to find two starting values for the line search. Those are marked as green. In practice, <code><a href="../reference/boottest.html">boottest()</a></code> needs to do some work to find them, but here we will skip this step.</p>
<p>We will start from the empirical confidence interval calculated by <code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code>:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt;                    2.5 %     97.5 %</span></span>
<span><span class="co">#&gt; (Intercept)  0.964052355 1.00325628</span></span>
<span><span class="co">#&gt; X           -0.007654199 0.03204427</span></span></code></pre></div>
<p>We create two sets of starting values by adding a value <span class="math inline">\(\epsilon \neq 0\)</span> to the confidence boundaries of the confidence set obtained by <code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fl">0.01</span></span>
<span></span>
<span><span class="va">startset1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>,<span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="va">epsilon</span>, <span class="va">epsilon</span><span class="op">)</span></span>
<span><span class="va">startset2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>,<span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="va">epsilon</span>, <span class="va">epsilon</span><span class="op">)</span></span></code></pre></div>
<p>With these starting values at hand, we can invert <span class="math inline">\(p(.)\)</span> numerically by a root finding procedure - we will run a simple bisection.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">invert_p_val</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, <span class="va">startset1</span>, <span class="va">startset2</span>, <span class="va">alpha</span><span class="op">)</span><span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># p-val - sign_level </span></span>
<span>  <span class="va">p_val_x_sign_level</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">r</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu">p_val</span><span class="op">(</span>X <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">y</span>, <span class="va">r</span><span class="op">)</span> <span class="op">-</span> <span class="va">alpha</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="co"># bisection for both startset1, startset2</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">startset1</span>, <span class="va">startset2</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">{</span> </span>
<span>                  </span>
<span>          <span class="va">tmp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/warning.html" class="external-link">suppressWarnings</a></span><span class="op">(</span><span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/uniroot.html" class="external-link">uniroot</a></span><span class="op">(</span>f <span class="op">=</span> <span class="va">p_val_x_sign_level</span>,</span>
<span>                                  lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,</span>
<span>                                  upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,</span>
<span>                                  tol <span class="op">=</span> <span class="fl">1e-08</span>,</span>
<span>                                  maxiter <span class="op">=</span> <span class="fl">10</span><span class="op">)</span><span class="op">$</span><span class="va">root</span><span class="op">)</span></span>
<span></span>
<span>          <span class="op">}</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/unlist.html" class="external-link">unlist</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre></div>
<p>Now, which confidence interval do we get from the numerical p-value inversion?</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">invert_p_val</span><span class="op">(</span>X <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">y</span>, startset1 <span class="op">=</span> <span class="va">startset1</span>, startset2 <span class="op">=</span> <span class="va">startset2</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -0.007654199  0.032044270</span></span></code></pre></div>
<p>As it turns out, this confidence interval is practically identical with the confidence interval based on estimated standard errors:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt;                    2.5 %     97.5 %</span></span>
<span><span class="co">#&gt; (Intercept)  0.964052355 1.00325628</span></span>
<span><span class="co">#&gt; X           -0.007654199 0.03204427</span></span></code></pre></div>
<p>We have successfully inverted p-values to obtain a confidence interval and have <em>not</em> calculated a standard error to compute the CI and have <em>not</em> used any asymptotic approximation in the process!</p>
</div>
</div>
<div class="section level3 unnumbered">
<h3 id="literature">Literature<a class="anchor" aria-label="anchor" href="#literature"></a>
</h3>
<div id="refs" class="references">
<div id="ref-djogbenou2019asymptotic">
<p>Djogbenou, Antoine A, James G MacKinnon, and Morten Ørregaard Nielsen. 2019. “Asymptotic Theory and Wild Bootstrap Inference with Clustered Errors.” <em>Journal of Econometrics</em> 212 (2): 393–412.</p>
</div>
<div id="ref-mackinnon2015wild">
<p>MacKinnon, James. 2015. “Wild Cluster Bootstrap Confidence Intervals.” <em>L’Actualité économique</em> 91 (1-2): 11–33.</p>
</div>
<div id="ref-mackinnon2022fast">
<p>MacKinnon, James G, Morten Nielsen, Matthew D Webb, and others. 2022. “Fast and Reliable Jackknife and Bootstrap Methods for Cluster-Robust Inference.”</p>
</div>
<div id="ref-mackinnon2022cluster">
<p>MacKinnon, James G, Morten Ørregaard Nielsen, and Matthew D Webb. 2022. “Cluster-Robust Inference: A Guide to Empirical Practice.” <em>Journal of Econometrics</em>.</p>
</div>
<div id="ref-mackinnon2018wild">
<p>MacKinnon, James G, and Matthew D Webb. 2018. “The Wild Bootstrap for Few (Treated) Clusters.” <em>The Econometrics Journal</em> 21 (2): 114–35.</p>
</div>
<div id="ref-roodman2019fast">
<p>Roodman, David, Morten Ørregaard Nielsen, James G MacKinnon, and Matthew D Webb. 2019. “Fast and Wild: Bootstrap Inference in Stata Using Boottest.” <em>The Stata Journal</em> 19 (1): 4–60.</p>
</div>
<div id="ref-webb2013reworking">
<p>Webb, Matthew D. 2013. “Reworking Wild Bootstrap Based Inference for Clustered Errors.” Queen’s Economics Department Working Paper.</p>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Alexander Fischer, David Roodman.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
