---
title: "FAQ / Practical Advice"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Practical_Advice}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## How many bootstrap iterations should I run? 

[MacKinnon, Nielsen and Webb (2023)](https://arxiv.org/pdf/2301.04527.pdf) write "In most cases, it is advisable to compute wild cluster bootstrap P values and/or confidence intervals using at least 9,999 bootstrap samples. This is usually not computationally difficult." Note that for many problems, running 99,999 bootstrap iterations via `fwildclusterboot` will take not more than a second. 

## Which weight types should I use? Why should I use Webb weights when the number of clusters is small?

In general, it is common practice to run the wild bootstrap with Rademacher weights. When the number of clusters is small (i.e. if the number of clusters G is smaller than 12), it is advised to use Webb weights. 

## What is the difference between the WRC and WRU? In other words, what does "imposing the null" on the data generating process mean? 

tba

## When should I impose the null on the dgp, and when not?


## How does one compute confidence intervals by "test inversion"?

tba

## Why is the "Fast and Wild" Algorithm so incredibly fast?

The short version: very (**very!**) clever use of linear algebra reduces the complexity of the computational problem from O(BN) to O(BG), with B being the number of bootstrap iterations, N the number of observations, and G the number of clusters. 




